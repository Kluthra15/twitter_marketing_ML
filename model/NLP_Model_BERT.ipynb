{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMmFIew6h4POZhJxXYUpVL2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kluthra15/twitter_marketing_ML/blob/main/NLP_Model_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydDBWD0pkXaZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "from bertopic import BERTopic\n",
        "from bertopic.vectorizers import ClassTfidfTransformer\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from bertopic.representation import TextGeneration\n",
        "from bertopic.representation import KeyBERTInspired\n",
        "from bertopic.representation import MaximalMarginalRelevance\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from umap import UMAP\n",
        "from transformers import pipeline, AutoModel\n",
        "from bertopic.representation import OpenAI\n",
        "from hdbscan import HDBSCAN\n",
        "import numpy as np\n",
        "\n",
        "# Build the pipeline with the current parameter settings\n",
        "stopwords_list      = list(stopwords.words('english')) + ['http', 'https', 'amp', 'com', 'gtgtgt', 'please', 'send', 'dm']\n",
        "\n",
        "vectorizer_model    = CountVectorizer(min_df=5,\n",
        "                                      ngram_range=(1,2),\n",
        "                                      stop_words=stopwords_list)\n",
        "\n",
        "embedding_model     = AutoModel.from_pretrained('roberta-base')\n",
        "\n",
        "umap_model          = UMAP(n_neighbors= 15,\n",
        "                           n_components= 7,\n",
        "                           min_dist= 0.1,\n",
        "                           random_state= 42)\n",
        "\n",
        "hdbscan_model       = HDBSCAN(min_cluster_size= 100,\n",
        "                              min_samples= 40,\n",
        "                              gen_min_span_tree=True,\n",
        "                              prediction_data=True)\n",
        "\n",
        "ctfidf = ClassTfidfTransformer(reduce_frequent_words=True)\n",
        "representation_model = KeyBERTInspired()\n",
        "\n",
        "model = BERTopic(\n",
        "    umap_model=umap_model,\n",
        "    hdbscan_model=hdbscan_model,\n",
        "    embedding_model=embedding_model,\n",
        "    vectorizer_model=vectorizer_model,\n",
        "    representation_model = representation_model,\n",
        "    ctfidf_model=ctfidf,\n",
        "    top_n_words=10,\n",
        "    min_topic_size=100,\n",
        "    language='english',\n",
        "    calculate_probabilities=True,\n",
        "    verbose=True,\n",
        "    nr_topics = 50\n",
        "    )\n",
        "\n",
        "# Fit the BERTopic model\n",
        "topics, probs = model.fit_transform(df_tweets_preprocessed['text_preprocessed'])\n",
        "\n",
        "# Calculate silhouette score\n",
        "silhouette_avg = silhouette_score(probs, hdbscan_model.labels_)\n",
        "\n",
        "print(silhouette_avg)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Method 1 - safetensors\n",
        "model.save(\"/content/drive/MyDrive/Colab_Notebooks/My_Models/\", serialization=\"safetensors\", save_ctfidf=True, save_embedding_model=embedding_model)\n",
        "\n",
        "# # Method 2 - pytorch\n",
        "model.save(\"/content/drive/MyDrive/Colab_Notebooks/My_Models/\", serialization=\"pytorch\", save_ctfidf=True, save_embedding_model=embedding_model)\n",
        "\n",
        "# # Method 3 - pickle\n",
        "model.save(\"/content/drive/MyDrive/Colab_Notebooks/My_Models/twitter_bert_model\", serialization=\"pickle\")"
      ],
      "metadata": {
        "id": "_Z0io-l8krbh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}